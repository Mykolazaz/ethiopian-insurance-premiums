{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91689d1",
   "metadata": {},
   "source": [
    "# Predicting Ethiopian Vehicle Insurance Premiums\n",
    "\n",
    "- The goal of this project is to clean, analyse and predict vehicle insurance premiums of the state-owned Ethiopian Insurance Corporation (one of the biggest insurance companies in Ethiopia).\n",
    "- The dataset we'll use describes vehicles, their insurance premiums and other insurance related atributes from July 2011 to June 2018. It can be found on [Mendeley Data](https://data.mendeley.com/datasets/34nfrk36dt/1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37555f6",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from scipy.stats import expon, kstest\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "insurance_data_1 = pd.read_csv(\"insuranceData/motor_data11-14lats.csv\")\n",
    "insurance_data_2 = pd.read_csv(\"insuranceData/motor_data14-2018.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24ccbb",
   "metadata": {},
   "source": [
    "## Predefined function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_and_premiums(ax, count_series, premium_series, xlabel):\n",
    "    index = count_series.index\n",
    "    x = np.arange(len(index))\n",
    "    w = 0.4\n",
    "\n",
    "    ax.bar(x - w/2, count_series.values, w, label=\"Policy Count\", color=\"tab:red\")\n",
    "    ax.set_ylabel(\"Policy Count\", color=\"tab:red\")\n",
    "    ax.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(index)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.bar(x + w/2, premium_series.loc[index].values, w, label=\"Premium Sum\", color=\"tab:blue\")\n",
    "    ax2.set_ylabel(\"Premium Sum\", color=\"tab:blue\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"tab:blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a004e",
   "metadata": {},
   "source": [
    "## Dataset overview\n",
    "\n",
    "Both of the provided dataset files include the same entry attributes and differ only in entry dates. They will need to be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e952f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = pd.concat([insurance_data_1, insurance_data_2], ignore_index=True)\n",
    "\n",
    "print(insurance_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a73ae",
   "metadata": {},
   "source": [
    "We have 802036 insurance policy records and 16 policy related attributes.\n",
    "\n",
    "Now let's look whether the provided attributes have been read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b56e4c",
   "metadata": {},
   "source": [
    "There are multiple entries regarding the same vehicle as it has to be reinsured at least every year. That can lead to up to 7 entries for the same vehicle with only the premium amout fluctuating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00010b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f31b2",
   "metadata": {},
   "source": [
    "Columns seem to have been read correctly. Let's now look at the values in individual columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a05bc6",
   "metadata": {},
   "source": [
    "### Object ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"OBJECT_ID\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335f16f",
   "metadata": {},
   "source": [
    "Some vehicles appear more that 7 times in the dataset. This can happen when the owner of a vehicle changes more than once per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13120d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[insurance_data[\"OBJECT_ID\"].astype(str) == \"5000116673\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44602e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(insurance_data[\"OBJECT_ID\"].value_counts() > 7).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56a862",
   "metadata": {},
   "source": [
    "There are a total of 7290 object IDs that apprear more than 7 times.\n",
    "\n",
    "It quickly becomes clear that we are dealing with a dataset with many errors. For the same object ID, there are entries that are not clearly logically intertwined. However, we can still perform predictive analysis under the presumption that each row in the dataset represents a unique vehicle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055e70c",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa068c",
   "metadata": {},
   "source": [
    "In the dataset, there are 3 unique sex values with 0 being legal entities, 1 - males and 2 - females. The number of insurance contracts in which men are the policyholders is 4.67 times greater that the number of contracts with female policyholders. That is due to women being less likely to have a drivers license in Ethiopia.\n",
    "\n",
    "Let's remap the value for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {0:\"LEGAL ENTITY\", 1:\"MALE\", 2:\"FEMALE\"}\n",
    "\n",
    "insurance_data[\"SEX\"] = insurance_data[\"SEX\"].map(sex_mapping)\n",
    "\n",
    "insurance_data[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"LOG_PREMIUM\"] = np.log(insurance_data[\"PREMIUM\"] + 1)\n",
    "\n",
    "sex_values = insurance_data[\"SEX\"].unique()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for sex in sex_values:\n",
    "    subset = insurance_data[insurance_data[\"SEX\"] == sex][\"LOG_PREMIUM\"]\n",
    "    plt.hist(subset, bins=30, alpha=0.5, label=str(sex), density=True)\n",
    "\n",
    "plt.xlabel(\"Log Premium\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127a94c",
   "metadata": {},
   "source": [
    "The distributions of premiums for males and females are practically inseparable. For legal entities, however, the premiums seem to be larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7cb2e",
   "metadata": {},
   "source": [
    "### Insurance start & end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8697572",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_BEGIN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_END\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca173454",
   "metadata": {},
   "source": [
    "There do not seem to be any obvious errors in the data. Yet, we must check whether there are entries where the insurance start date is later than the end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54392fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_BEGIN\"] = pd.to_datetime(insurance_data[\"INSR_BEGIN\"], format=\"%d-%b-%y\")\n",
    "\n",
    "insurance_data[\"INSR_END\"] = pd.to_datetime(insurance_data[\"INSR_END\"], format=\"%d-%b-%y\")\n",
    "\n",
    "end_greater_start = insurance_data[\"INSR_BEGIN\"] > insurance_data[\"INSR_END\"]\n",
    "length = len(end_greater_start[end_greater_start == True])\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec81d21",
   "metadata": {},
   "source": [
    "No end values are earlier than start values. We can now visualize the variable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_START_MONTH\"] = pd.to_datetime(insurance_data[\"INSR_BEGIN\"], format=\"%d-%b-%y\").dt.month\n",
    "insurance_data[\"INSR_START_YEAR\"] = pd.to_datetime(insurance_data[\"INSR_BEGIN\"], format=\"%d-%b-%y\").dt.year\n",
    "\n",
    "start_months = insurance_data[\"INSR_START_MONTH\"].value_counts().sort_index()\n",
    "start_months_premium = insurance_data.groupby(\"INSR_START_MONTH\")[\"PREMIUM\"].sum()\n",
    "\n",
    "start_years = insurance_data[\"INSR_START_YEAR\"].value_counts().sort_index()\n",
    "start_years_premium = insurance_data.groupby(\"INSR_START_YEAR\")[\"PREMIUM\"].sum()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "plot_counts_and_premiums(axes[0], start_months, start_months_premium, \"Month\")\n",
    "plot_counts_and_premiums(axes[1], start_years, start_years_premium, \"Year\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e5a39",
   "metadata": {},
   "source": [
    "From the charts it becomes clear that policy count closely correlates with premium sums with regard to both the month and the year of the insurance start date. One month, July, stand out as the month in which the most policies are introduced. Also, January and December seem to be months where more policies are introduced than usual. This could be due to accounting methods in which a policy signed near the end of the fiscal year is counted as being signed in the next year. In terms of the trend regarding the year, there is a clear pattern of growth from 2011 to 2017 and a sharp drop off of new policies in 2018. The drop off can be explained by the end of data collection period being June of 2018. We can check whether growth in the month of June in the respective years is equally as rapid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_june = insurance_data[(insurance_data[\"INSR_START_YEAR\"].isin([2017, 2018])) & (insurance_data[\"INSR_START_MONTH\"] < 7)]\n",
    "\n",
    "before_june.groupby(\"INSR_START_YEAR\").size().reset_index(name=\"Policy Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff979cf8",
   "metadata": {},
   "source": [
    "The pace of growth is about the same.\n",
    "\n",
    "Let\"s also create a dummy variable for insurance start days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_START_DAY\"] = pd.to_datetime(insurance_data[\"INSR_BEGIN\"], format=\"%d-%b-%y\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_stats = insurance_data.groupby(\"INSR_START_DAY\").agg(\n",
    "    policy_count=(\"PREMIUM\", \"count\"),\n",
    "    premium_sum=(\"PREMIUM\", \"sum\")\n",
    ")\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "day_stats[\"policy_count\"].plot(kind=\"bar\", ax=ax1, position=0, width=0.4, label=\"Policy Count\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "day_stats[\"premium_sum\"].plot(kind=\"bar\", color=\"red\", ax=ax2, position=1, width=0.4, label=\"Premium Sum\")\n",
    "\n",
    "ax1.set_xlabel(\"Day\")   \n",
    "ax1.set_ylabel(\"Number of Policies\")\n",
    "ax2.set_ylabel(\"Total Premium Sum\", color=\"red\")\n",
    "plt.title(\"Policies and Premium Sums by Start Day\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e26ad",
   "metadata": {},
   "source": [
    "The largest of policies were registered on the 1st and the 8th. This is abnormal, and the distribution should be uniform. This issue should be escalated to the data owners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf29d5",
   "metadata": {},
   "source": [
    "### Effective year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35081caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"EFFECTIVE_YR\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09436858",
   "metadata": {},
   "source": [
    "The effective year variable indicates what year the policy came into effect (was first insured with the company). There are numerous records that indicate a year before the historic start date of the dataset (2011).\n",
    "\n",
    "Yet, the column contains values that are not indicative of a number and should be removed. Since there are a total of 802036 records, we can afford to lose quite a few. We also need to convert the years into a four-digit number as a two-digit year encoding is only common on legacy data storage systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd50f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = insurance_data[insurance_data[\"EFFECTIVE_YR\"].astype(str).str.match(r\"^\\d{2}$\")]\n",
    "\n",
    "def convert_year(y):\n",
    "    y = int(y)\n",
    "    if y > 18:\n",
    "        return 1900 + y\n",
    "    else:\n",
    "        return 2000 + y\n",
    "\n",
    "insurance_data[\"EFFECTIVE_YR_FULL\"] = insurance_data[\"EFFECTIVE_YR\"].apply(convert_year)\n",
    "\n",
    "insurance_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44030f",
   "metadata": {},
   "source": [
    "After cleaning the effective year column, we have lost 1171 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = insurance_data[\"EFFECTIVE_YR_FULL\"].value_counts().sort_index()\n",
    "\n",
    "year_counts = year_counts[\n",
    "    (year_counts.index >= 1992) &\n",
    "    (year_counts.index <= 2018)\n",
    "]\n",
    "\n",
    "year_counts.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Effective Year\")\n",
    "plt.ylabel(\"Policy Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = insurance_data[\"EFFECTIVE_YR_FULL\"].value_counts().sort_index()\n",
    "print(year_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d22951",
   "metadata": {},
   "source": [
    "The data shows that most of the insured vehicles were first insured in 2011 and later. After contacting the postdoctoral fellow that published the dataset, I was informed that the meaning of this variable is not very well documented. There are values of 1947 and prior, eventhough, in Ethiopia, the first motor insurance was issued in 1947. This variable will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ad62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.drop(columns=[\"EFFECTIVE_YR\", \"EFFECTIVE_YR_FULL\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0df4d4",
   "metadata": {},
   "source": [
    "### Insurance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbe8b1",
   "metadata": {},
   "source": [
    "There are a total of three types of insurance: 1201 - private, 1202 - commercial and 1204 - motor trade road risk (for motor trade workers that drive vehicles they do not personally own, such as mechanics when testing repaired vehicles).\n",
    "\n",
    "Let's change the values so they make more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_type_mapping = {1202:\"PRIVATE\", 1201:\"COMMERCIAL\", 1204:\"MOTOR TRADE\"}\n",
    "\n",
    "insurance_data[\"INSR_TYPE\"] = insurance_data[\"INSR_TYPE\"].map(insurance_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc469f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ff467",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_type_values = insurance_data[\"INSR_TYPE\"].unique()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for type in insurance_type_values:\n",
    "    subset = insurance_data[insurance_data[\"INSR_TYPE\"] == type][\"LOG_PREMIUM\"]\n",
    "    plt.hist(subset, bins=30, alpha=0.5, label=str(type), density=True)\n",
    "\n",
    "plt.xlabel(\"Log Premium\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60435fe5",
   "metadata": {},
   "source": [
    "Here, motor trade insurance premiums are not as high as private and commercial premiums. Commercial and private insurance premiums are distributed around the same. It should also be noted that the log premium value range is similar for later mentioned groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbeefb2",
   "metadata": {},
   "source": [
    "### Insured value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0866ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSURED_VALUE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1ee32",
   "metadata": {},
   "source": [
    "343235 vehicles in the dataset have no provided insurance value. Insured value of 0 means the policyholder has the liability insurance coverage only, not the comprehensive coverage while insured value higher than 0 indicates comprehensive coverage.\n",
    "\n",
    "The difference between the liability and comprehensive insurance is that liability insurance covers damage or injury you cause to other people or their property (and not repairs to your vehicle) and comprehensive insurance covers non-collision damage to your own car.\n",
    "\n",
    "For the purpose of developing a model, we may create an additional variable that indicates the type of insurance the policyholder has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28386bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSR_COVER\"] = np.where(\n",
    "    insurance_data[\"INSURED_VALUE\"] == 0,\n",
    "    \"LIABILITY\",\n",
    "    \"COMPREHENSIVE\"\n",
    ")\n",
    "\n",
    "insurance_data[\"INSR_COVER\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"INSURED_VALUE\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e893df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(insurance_data[\"INSURED_VALUE\"], insurance_data[\"PREMIUM\"], alpha=0.2)\n",
    "plt.xlabel(\"Insured Value\")\n",
    "plt.ylabel(\"Premium\")\n",
    "plt.xlim([-2000000, 50000000])\n",
    "plt.ylim([-20000, 400000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cd2f7",
   "metadata": {},
   "source": [
    "It is unlikely that there is a strong linear relation between insured value and premiums."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d92c6b",
   "metadata": {},
   "source": [
    "### Year of production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d72714",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PROD_YEAR\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PROD_YEAR\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60989e50",
   "metadata": {},
   "source": [
    "We have NaN values in our dataset. Instead of removing them, we can fill them with median values and preserve the central tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PROD_YEAR\"] = insurance_data[\"PROD_YEAR\"].fillna(insurance_data[\"PROD_YEAR\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PROD_YEAR\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53767bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PROD_YEAR\"].plot(kind=\"hist\", bins=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe9103",
   "metadata": {},
   "source": [
    "The production year variable is heavily left-skewed, but are no abnormalities in this attribute. We can create an additional variable for vehicle age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b91a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_insr_date = pd.to_datetime(insurance_data[\"INSR_BEGIN\"].max())\n",
    "\n",
    "prod_year_dt = pd.to_datetime(insurance_data[\"PROD_YEAR\"], format=\"%Y\")\n",
    "\n",
    "insurance_data[\"VEHICLE_AGE\"] = (max_insr_date - prod_year_dt).dt.days / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a37185",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(insurance_data[\"VEHICLE_AGE\"], insurance_data[\"PREMIUM\"], alpha=0.1)\n",
    "plt.xlabel(\"Vehicle Age\")\n",
    "plt.ylabel(\"Premium\")\n",
    "plt.ylim([-20000, 300000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12388e2",
   "metadata": {},
   "source": [
    "Premiums tend to stabilize and decrease as vehicles age. There are likely few antique vehicles in Ethiopia, so practically all vehicles become less valuable with age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dde2fc",
   "metadata": {},
   "source": [
    "### Number of seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9333ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"SEATS_NUM\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"SEATS_NUM\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062328f3",
   "metadata": {},
   "source": [
    "There are a total of 59703 vehicles with 0 seats which is impossible. Also, the number of seats should not exceed 256 (seats in the largest bus in the world). Other values will be considered correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = insurance_data[(insurance_data[\"SEATS_NUM\"] > 0) & (insurance_data[\"SEATS_NUM\"] <= 256)]\n",
    "\n",
    "print(insurance_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7347cc",
   "metadata": {},
   "source": [
    "### Carrying capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd115a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"CARRYING_CAPACITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35000dcd",
   "metadata": {},
   "source": [
    "It is clear that the seat number variable and the carrying capacity variable are not clearly differentiated. They have been mixed up and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.drop(columns=[\"SEATS_NUM\", \"CARRYING_CAPACITY\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c74825",
   "metadata": {},
   "source": [
    "### Vehicle type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269368d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"TYPE_VEHICLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093d8fdc",
   "metadata": {},
   "source": [
    "Nothing out of the ordinary here. We will capitalize the letters for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"TYPE_VEHICLE\"] = insurance_data[\"TYPE_VEHICLE\"].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70205429",
   "metadata": {},
   "source": [
    "### Vehicle Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"CCM_TON\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"CCM_TON\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea40c7b7",
   "metadata": {},
   "source": [
    "This variable is related to the weight of the vehicle. Since it is not clearly described how and what units are being used, we will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40611407",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.drop(columns=[\"CCM_TON\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bd1e9",
   "metadata": {},
   "source": [
    "### Vehicle maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"MAKE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfe48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"MAKE\"].value_counts()[insurance_data[\"MAKE\"].value_counts() <= 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ad2af",
   "metadata": {},
   "source": [
    "There is a large number of vehicle maker names that are not representative of the manufacturer or are miss-spellings of the brand name, with 'TOYOTA MERCHEDIS' being the most humorous one. Since there is a total number of 657 unique brands, individual corrections would be too cumbersome. Instead, we can use a list of car names and check for matches in the dataset.\n",
    "\n",
    "We will scrape a complete list of car brands from a car brand [website](https://www.carlogos.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.carlogos.org/car-brands-a-z/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/115.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "brands = []\n",
    "\n",
    "for dd in soup.find_all(\"dd\"):\n",
    "    a_tag = dd.find(\"a\")\n",
    "    if a_tag and a_tag.text.strip():\n",
    "        brands.append(a_tag.text.strip())\n",
    "\n",
    "brands = list(dict.fromkeys(brands))\n",
    "\n",
    "print(brands)\n",
    "\n",
    "len(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ba5d3",
   "metadata": {},
   "source": [
    "The website states that there are 383 car brands on the website. The beginning of the list contains countries and the end contains other unrelated text. That should prove easy to clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_clean = brands[21:-8]\n",
    "\n",
    "remove_list = [\"Mercedes-Benz\", \"Audi Sport\", \"BMW M\", \"Chevrolet Corvette\", \"Ford Mustang\", \"Nissan GT-R\", \"Toyota Alphard\", \"Toyota Century\", \"Toyota Crown\"]\n",
    "brands_clean = [b for b in brands_clean if b not in remove_list]\n",
    "\n",
    "brands_clean = [\"Mercedes\" if b == \"Mercedes-AMG\" else b for b in brands_clean]\n",
    "\n",
    "print(brands_clean)\n",
    "\n",
    "len(brands_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd6e98",
   "metadata": {},
   "source": [
    "We can now look for matching brands in our dataset. For that we will use the fuzzywuzzy library and search for matches using the Levenshtein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = insurance_data[insurance_data[\"MAKE\"].str.strip() != \"*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_makes = insurance_data[\"MAKE\"].unique()\n",
    "\n",
    "def match_brand(brand):\n",
    "    match, score = process.extractOne(brand, brands_clean)\n",
    "    return match if score >= 80 else \"UNKNOWN\"\n",
    "\n",
    "mapping = {make: match_brand(make) for make in unique_makes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808acbf",
   "metadata": {},
   "source": [
    "We can review and map the remaining brands that were not detected as matches manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mapping = {\n",
    "    \"MERCEEDICE\": \"Mercedes\",\n",
    "    \"MERCEEDES\": \"Mercedes\",\n",
    "    \"MERCHEDES\": \"Mercedes\",\n",
    "    \"MERCEDICE\": \"Mercedes\",\n",
    "    \"MERCEDIS\": \"Mercedes\",\n",
    "    \"DUNGFING\": \"Dongfeng\",\n",
    "    \"GEEP\": \"Jeep\",\n",
    "    \"PEAGOUT\": \"Peugeot\",\n",
    "    \"PAGOT\": \"Peugeot\",\n",
    "    \"PEJOT\": \"Peugeot\",\n",
    "    \"LAND CRUISER\": \"Toyota\",\n",
    "    \"T0Y0TA\": \"Toyota\",\n",
    "    \"COROLLA\": \"Toyota\",\n",
    "    \"RAV4\": \"Toyota\",\n",
    "    \"VOLSVAGON\": \"Volkswagen\",\n",
    "    \"PASSAT\": \"Volkswagen\",\n",
    "    \"HYUNDI GETZ\": \"Hyundai\",\n",
    "    \"DISCOVER\": \"Land Rover\",\n",
    "    \"FOED\": \"Ford\",\n",
    "    \"BMB\": \"BMW\"\n",
    "}\n",
    "\n",
    "combined_mapping = {**mapping, **manual_mapping}\n",
    "\n",
    "insurance_data[\"MANUFACTURER\"] = insurance_data[\"MAKE\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"MANUFACTURER\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6d9fe",
   "metadata": {},
   "source": [
    "### Primary function of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214215f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"USAGE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb89aaf",
   "metadata": {},
   "source": [
    "All functions seem valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e74d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"USAGE\"] = insurance_data[\"USAGE\"].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500b076",
   "metadata": {},
   "source": [
    "### Paid claim sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"CLAIM_PAID\"] = insurance_data[\"CLAIM_PAID\"].replace(np.nan, 0)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "print(insurance_data[\"CLAIM_PAID\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_claim_paid = np.log(insurance_data[\"CLAIM_PAID\"] + 1)\n",
    "\n",
    "log_claim_paid.plot(kind=\"hist\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbe170",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(insurance_data[insurance_data[\"CLAIM_PAID\"] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040a35c",
   "metadata": {},
   "source": [
    "The payout values seem realistic since they are in Ethiopian birr. The largest paid sum is around 1,100,000 USD.\n",
    "\n",
    "There is one issue: even the log-transformed variable does not resemble any known distribution. Thus, we can create an additional variable that might perform better in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"WAS_CLAIM_PAID\"] = np.where(insurance_data['CLAIM_PAID'] > 0, True, False)\n",
    "\n",
    "insurance_data[\"WAS_CLAIM_PAID\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4522c",
   "metadata": {},
   "source": [
    "### Insurance premium\n",
    "\n",
    "The premium amounts are provided in Ethiopian birr (1000 Birr = 7,3 USD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3596c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data[\"PREMIUM\"][insurance_data[\"PREMIUM\"] <= 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ba709",
   "metadata": {},
   "source": [
    "There are 10 vehicles with a premium of 0 or less. This is not acceptable and we will remove them. I was informed by the publisher of the dataset that the company follows a principle of \"No premium, no insurance\", meaning they are no longer insured. This method of record keeping is ineffective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = insurance_data[insurance_data[\"PREMIUM\"] > 0]\n",
    "\n",
    "insurance_data[\"PREMIUM\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51351e",
   "metadata": {},
   "source": [
    "From the variable description it becomes clear that it is nowhere close to normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27753503",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = expon.fit(insurance_data[\"PREMIUM\"])\n",
    "\n",
    "x = np.linspace(0, 50000, 1000)\n",
    "pdf = expon.pdf(x, *params)\n",
    "\n",
    "plt.hist(insurance_data[\"PREMIUM\"], bins=500, density=True)\n",
    "plt.plot(x, pdf, 'r')\n",
    "plt.xlim([0, 50000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a08b6",
   "metadata": {},
   "source": [
    "The distribution closely resembles an exponential one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, p_value = kstest(insurance_data[\"PREMIUM\"], \"expon\", args=params)\n",
    "\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e25c02",
   "metadata": {},
   "source": [
    "As the p-value is less than 0.05, we fail to reject the null hypothesis. This distribution might as well exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a801a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_premiums = np.log(insurance_data[\"PREMIUM\"])\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6), gridspec_kw={\"height_ratios\": [1, 4]})\n",
    "\n",
    "axes[0].boxplot(log_premiums, vert=False, widths=0.6)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "axes[1].hist(log_premiums, bins=25)\n",
    "axes[1].set_xlabel(\"Log Premium\")\n",
    "\n",
    "plt.tight_layout(h_pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682c3cb",
   "metadata": {},
   "source": [
    "### Additional variables for modelling\n",
    "\n",
    "From the existing dataset variable we can crate additional variables that, in theory, could provide better model outcomes.\n",
    "\n",
    "#### Previous claim paid\n",
    "\n",
    "If a vehicle is dangerous to operate this could be reflected in the total claim payout sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = insurance_data.sort_values([\"OBJECT_ID\", \"INSR_BEGIN\"])\n",
    "\n",
    "sorted_df[\"PREVIOUS_CLAIM_PAID\"] = (\n",
    "    sorted_df.groupby(\"OBJECT_ID\")[\"CLAIM_PAID\"]\n",
    "    .cumsum()\n",
    "    .shift(fill_value=0)\n",
    ")\n",
    "\n",
    "insurance_data[\"PREVIOUS_CLAIM_PAID\"] = sorted_df[\"PREVIOUS_CLAIM_PAID\"].reindex(insurance_data.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d3f96",
   "metadata": {},
   "source": [
    "#### Previous policy holders\n",
    "\n",
    "A greater number of previous reinsurances could also indicate greater risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a47407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = insurance_data.sort_values([\"OBJECT_ID\", \"INSR_BEGIN\"])\n",
    "\n",
    "sorted_df[\"PREVIOUS_POLICYHOLDERS\"] = (\n",
    "    sorted_df.groupby(\"OBJECT_ID\").cumcount()\n",
    ")\n",
    "\n",
    "insurance_data[\"PREVIOUS_POLICYHOLDERS\"] = sorted_df[\"PREVIOUS_POLICYHOLDERS\"].reindex(insurance_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857a159",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366581a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35675d",
   "metadata": {},
   "source": [
    "We are left with 15 variables that could be used for modelling: `SEX`, `INSR_TYPE`, `INSURED_VALUE`, `PROD_YEAR`, `TYPE_VEHICLE`, `USAGE`, `CLAIM_PAID`, `INSR_COVER`, `INSR_START_DAY/MONTH/YEAR`, `INSR_COVER`, `VEHICLE_AGE`, `MANUFACTURER`, `WAS_CLAIM_PAID`, `PREVIOUS_CLAIM_PAID` and `PREVIOUS_POLICYHOLDERS`.\n",
    "\n",
    "We will select variables by using R<sup>2</sup> as a guiding measure.\n",
    "\n",
    "#### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "\n",
    "X = insurance_data[[\"SEX\", \"INSR_TYPE\", \"INSURED_VALUE\", \"PROD_YEAR\", \"TYPE_VEHICLE\", \"USAGE\", \"INSR_COVER\", \"CLAIM_PAID\"]].copy()\n",
    "\n",
    "X = pd.get_dummies(X, columns=[\"SEX\", \"INSR_TYPE\", \"PROD_YEAR\", \"TYPE_VEHICLE\", \"USAGE\", \"INSR_COVER\"], drop_first=True)\n",
    "\n",
    "Y = insurance_data[\"PREMIUM\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=87)\n",
    "\n",
    "model1.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model1.predict(X_test)\n",
    "\n",
    "r_sq = model1.score(X_test, Y_test)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "r_sq, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(Y_test, Y_pred, alpha=0.1)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()],\n",
    "             [Y_test.min(), Y_test.max()],\n",
    "             'r')\n",
    "axes[0].set_title(\"Accuracy Plot\")\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(Y_pred, Y_test - Y_pred, alpha=0.1)\n",
    "axes[1].axhline(y=0, color='r')\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Residual Plot\")\n",
    "\n",
    "axes[2].hist(Y_test - Y_pred, bins=30, density=True)\n",
    "axes[2].set_xlabel(\"Residuals\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "axes[2].set_title(\"Distribution of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c758842",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "print(f\"Correlation: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13688fe",
   "metadata": {},
   "source": [
    "With almost all variables included in the model, we are getting an R<sup>2</sup> of 0.66. This is far from ideal, especially considering that we have not yet selected the best regressors.\n",
    "\n",
    "#### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    "\n",
    "X = insurance_data[[\"INSR_TYPE\", \"INSURED_VALUE\", \"TYPE_VEHICLE\", \"USAGE\"]].copy()\n",
    "\n",
    "X = pd.get_dummies(X, columns=[\"INSR_TYPE\", \"TYPE_VEHICLE\", \"USAGE\"], drop_first=True)\n",
    "\n",
    "Y = insurance_data[\"PREMIUM\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=87)\n",
    "\n",
    "model2.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model2.predict(X_test)\n",
    "\n",
    "r_sq = model2.score(X_test, Y_test)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "r_sq, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8094aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(Y_test, Y_pred, alpha=0.1)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()],\n",
    "             [Y_test.min(), Y_test.max()],\n",
    "             \"r\")\n",
    "axes[0].set_title(\"Accuracy Plot\")\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(Y_pred, Y_test - Y_pred, alpha=0.1)\n",
    "axes[1].axhline(y=0, color=\"r\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Residual Plot\")\n",
    "\n",
    "axes[2].hist(Y_test - Y_pred, bins=30, density=True)\n",
    "axes[2].set_xlabel(\"Residuals\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "axes[2].set_title(\"Distribution of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaca9b3",
   "metadata": {},
   "source": [
    "After dropping the less influential variables through backward selection, we are left with 4 variables and an R<sup>2</sup> of 0.625. That greatly simplified our model while providing similar results, but it quickly becomes clear that linear regression is not the ideal model candidate for premium predictions. The distribution of errors is nowhere near normal and quite a few of linear regression assumptions are not met: linearity, homoscedasticity. The relationship between the regressors and premium values is not linear. Different models should be tested for their predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba8016",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "#### Model #3\n",
    "\n",
    "Another model that we could test is XGBoost since it can handle non-linear relationships between variables and can potencially achieve better accuracy. We'll begin by adding all possible variables into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f097f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance_data[[\n",
    "    \"SEX\", \"INSR_TYPE\", \"INSURED_VALUE\", \"CLAIM_PAID\",\n",
    "    \"INSR_COVER\", \"MANUFACTURER\", \"TYPE_VEHICLE\", \"USAGE\",\n",
    "    \"PROD_YEAR\", \"INSR_START_MONTH\", \"INSR_START_YEAR\",\n",
    "    \"INSR_START_DAY\", \"VEHICLE_AGE\", \"WAS_CLAIM_PAID\",\n",
    "    \"PREVIOUS_CLAIM_PAID\", \"PREVIOUS_POLICYHOLDERS\"\n",
    "]].copy()\n",
    "\n",
    "X[\"INSURED_VALUE\"] = np.log1p(X[\"INSURED_VALUE\"] + 1)\n",
    "X[\"CLAIM_PAID\"] = np.log1p(X[\"CLAIM_PAID\"] + 1)\n",
    "\n",
    "X = pd.get_dummies(\n",
    "    X,\n",
    "    columns=[\"SEX\", \"INSR_TYPE\", \"INSR_COVER\", \"MANUFACTURER\", \"TYPE_VEHICLE\", \"USAGE\",\n",
    "             \"INSR_START_MONTH\", \"INSR_START_YEAR\", \"INSR_START_DAY\",\n",
    "             \"WAS_CLAIM_PAID\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "Y = insurance_data[\"PREMIUM\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=87\n",
    ")\n",
    "\n",
    "model3 = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=87,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model3.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model3.predict(X_test)\n",
    "\n",
    "r_sq = r2_score(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f\"R²: {r_sq:.4f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "plot_importance(model3, max_num_features=20, importance_type='weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(Y_test, Y_pred, alpha=0.1)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()],\n",
    "             [Y_test.min(), Y_test.max()],\n",
    "             \"r\")\n",
    "axes[0].set_title(\"Accuracy Plot\")\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(Y_pred, Y_test - Y_pred, alpha=0.1)\n",
    "axes[1].axhline(y=0, color=\"r\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Residual Plot\")\n",
    "\n",
    "axes[2].hist(Y_test - Y_pred, bins=30, density=True)\n",
    "axes[2].set_xlabel(\"Residuals\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "axes[2].set_title(\"Distribution of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fe463",
   "metadata": {},
   "source": [
    "With only a model switch and all variables used we are getting an R<sup>2</sup> of 0.85. That is a great improvement over 0.625. Our accuracy plot data points are much more concentrated around the accuracy line. The residual plot still shows non-random concentration around the line and the spike around 0 in the residual distribution is quite normal as it shows that the model is accurate for most of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b6b57",
   "metadata": {},
   "source": [
    "#### Model #4\n",
    "\n",
    "Still, there is room for improvement. We can remove that less meaningful variables from the feature importance chart and log-transform the premium values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf797e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance_data[[\n",
    "    \"SEX\", \"INSR_TYPE\", \"INSURED_VALUE\",\n",
    "    \"INSR_COVER\", \"TYPE_VEHICLE\", \"PROD_YEAR\",\n",
    "    \"VEHICLE_AGE\", \"WAS_CLAIM_PAID\",\n",
    "    \"PREVIOUS_CLAIM_PAID\", \"PREVIOUS_POLICYHOLDERS\"\n",
    "]].copy()\n",
    "\n",
    "X[\"INSURED_VALUE\"] = np.log1p(X[\"INSURED_VALUE\"] + 1)\n",
    "\n",
    "X = pd.get_dummies(\n",
    "    X,\n",
    "    columns=[\"SEX\", \"INSR_TYPE\", \"INSR_COVER\", \"TYPE_VEHICLE\", \"WAS_CLAIM_PAID\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "Y = insurance_data[\"LOG_PREMIUM\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=87\n",
    ")\n",
    "\n",
    "model3 = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=87,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model3.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model3.predict(X_test)\n",
    "\n",
    "r_sq = r2_score(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f\"R²: {r_sq:.4f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "plot_importance(model3, max_num_features=20, importance_type='weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a324a7",
   "metadata": {},
   "source": [
    "After feature selection, we are left with 10 meaningful variables. Some variables that were quite good predictors, such as insurance start day, were not keep as they would be known to the insurer before. Other variables, such as previous policy holders and previous claim paid, that were feature-enginnered proved extemely valuable. Also, the log-transformation of premiums also improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f03a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(Y_test, Y_pred, alpha=0.05)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()],\n",
    "             [Y_test.min(), Y_test.max()],\n",
    "             \"r\")\n",
    "axes[0].set_title(\"Accuracy Plot\")\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(Y_pred, Y_test - Y_pred, alpha=0.05)\n",
    "axes[1].axhline(y=0, color=\"r\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Residual Plot\")\n",
    "\n",
    "axes[2].hist(Y_test - Y_pred, bins=30, density=True)\n",
    "axes[2].set_xlabel(\"Residuals\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "axes[2].set_title(\"Distribution of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5657ad",
   "metadata": {},
   "source": [
    "As we can see from the accuracy plot, the data points have enveloped the accuracy line, with the same being in the residual plot. The distribution of residuals have also taken a more normal-looking distribution with the spike at 0 being less pronounced. The lines that appear in the accuracy & residuals plots are most likely caused by rounded insurance premium values in the original dataset.\n",
    "\n",
    "#### Bayesian optimization\n",
    "\n",
    "One other way that could improve the machine learning model is bayesian optimization. Instead of going through all available parameter combinations, we can use stochastic methods to look for the minimum in our loss function. For that, we'll use the hyperopt library functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "    n_jobs=-1,\n",
    "    random_state=87,\n",
    "    tree_method='hist',\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'max_depth': Integer(3, 12),\n",
    "    'learning_rate': Real(0.005, 0.2, prior='log-uniform'),\n",
    "    'subsample': Real(0.6, 1.0, prior='uniform'),\n",
    "    'colsample_bytree': Real(0.6, 1.0, prior='uniform'),\n",
    "    'gamma': Real(0, 5, prior='uniform'),\n",
    "    'min_child_weight': Integer(1, 10)\n",
    "}\n",
    "\n",
    "optimizer = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=1,\n",
    "    random_state=87\n",
    ")\n",
    "\n",
    "optimizer.fit(X_train, Y_train)\n",
    "\n",
    "print(f\"Best parameters found: {optimizer.best_params_}\")\n",
    "print(f\"Best CV score (MAE): {-optimizer.best_score_:.4f}\")\n",
    "\n",
    "Y_pred = optimizer.predict(X_test)\n",
    "\n",
    "r_sq = r2_score(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f\"\\nFinal R² on Test Set: {r_sq:.4f}\")\n",
    "print(f\"Final MAE on Test Set: {mae:.2f}\")\n",
    "\n",
    "\n",
    "final_model = optimizer.best_estimator_\n",
    "plot_importance(final_model, max_num_features=20, importance_type='weight')\n",
    "plt.title(\"XGBoost Feature Importance (Best Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab654d7",
   "metadata": {},
   "source": [
    "After testing 100 combinations of variables the minimum of loss function of 0.27 was achieved by looking for the lowest mean absolute error. With the optimal hyperparamets, the model achieved an R<sup>2</sup> of 0.9058, an improvement of 0.0124 over the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(Y_test, Y_pred, alpha=0.1)\n",
    "axes[0].plot([Y_test.min(), Y_test.max()],\n",
    "             [Y_test.min(), Y_test.max()],\n",
    "             \"r\")\n",
    "axes[0].set_title(\"Accuracy Plot\")\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(Y_pred, Y_test - Y_pred, alpha=0.1)\n",
    "axes[1].axhline(y=0, color=\"r\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Residual Plot\")\n",
    "\n",
    "axes[2].hist(Y_test - Y_pred, bins=30, density=True)\n",
    "axes[2].set_xlabel(\"Residuals\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "axes[2].set_title(\"Distribution of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
